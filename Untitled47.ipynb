{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHNpuuQd4gRUl6uf5ydRDD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sukriramli/hs-2022-explorer/blob/main/Untitled47.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6URh_pziJ3s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import joblib\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# 1. Data Loading\n",
        "repo_url = \"https://github.com/datasets/harmonized-system.git\"\n",
        "repo_name = \"harmonized-system\"\n",
        "\n",
        "if not os.path.exists(repo_name):\n",
        "    os.system(f\"git clone {repo_url}\")\n",
        "\n",
        "data_dir = f\"./{repo_name}/data\"\n",
        "file_name = 'harmonized-system.csv'\n",
        "file_path = os.path.join(data_dir, file_name)\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(file_path, low_memory=True)\n",
        "    print(\"Data loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    exit()\n",
        "\n",
        "# 2. Data Cleaning and Preprocessing\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        return text\n",
        "    return \"\"\n",
        "\n",
        "if 'description' in df.columns:\n",
        "    df['cleaned_description'] = df['description'].apply(clean_text)\n",
        "\n",
        "if 'section' in df.columns:\n",
        "    section_counts = df['section'].value_counts()\n",
        "    top_20_sections = section_counts.index[:20]\n",
        "    df_top20 = df[df['section'].isin(top_20_sections)]\n",
        "\n",
        "if 'description' in df.columns:\n",
        "    df['sentiment'] = df['description'].apply(lambda x: TextBlob(x).sentiment.polarity if isinstance(x, str) else 0)\n",
        "\n",
        "# 3. Train Relevance Prediction Model (using dummy relevance data for demonstration)\n",
        "df['relevance'] = (df['sentiment'] + 1) / 2  # Dummy relevance based on sentiment\n",
        "X = df[['sentiment']]\n",
        "y = df['relevance']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Train Custom Word Embedding Model\n",
        "sentences = df['cleaned_description'].apply(lambda x: x.split()).tolist()\n",
        "custom_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "custom_model.save('custom_word2vec_model.model')\n",
        "\n",
        "# Load the custom word embedding model\n",
        "custom_model = Word2Vec.load('custom_word2vec_model.model')\n",
        "\n",
        "# --- Searchbox and Search Functionality ---\n",
        "\n",
        "def search_descriptions(search_term):\n",
        "    search_term = search_term.lower()\n",
        "\n",
        "    # Combine relevant columns for searching\n",
        "    df['combined_text'] = df['cleaned_description'].astype(str) + ' ' + \\\n",
        "                          df['hscode'].astype(str) + ' ' + \\\n",
        "                          df['section'].astype(str)\n",
        "\n",
        "    # Check if the search term is numeric (HS code)\n",
        "    if search_term.isdigit():\n",
        "        results = df[df['hscode'].astype(str).str.contains(search_term, na=False, regex=False)].copy()\n",
        "        # Ensure 'predicted_relevance' column is created and cast to float\n",
        "        if 'predicted_relevance' not in results.columns:\n",
        "            results['predicted_relevance'] = 0.0\n",
        "        results['predicted_relevance'] = 1.0  # Assign a default relevance for HS code search\n",
        "    else:\n",
        "        # Calculate TF-IDF vectors\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = vectorizer.fit_transform(df['combined_text'])\n",
        "        search_vector = vectorizer.transform([search_term])\n",
        "\n",
        "        # Calculate cosine similarity\n",
        "        from sklearn.metrics.pairwise import cosine_similarity\n",
        "        cosine_similarities = cosine_similarity(search_vector, tfidf_matrix).flatten()\n",
        "        df['relevance'] = cosine_similarities\n",
        "\n",
        "        # Predict relevance (using .loc to avoid SettingWithCopyWarning)\n",
        "        results = df[df['combined_text'].str.contains(search_term, na=False, regex=False)].copy()\n",
        "\n",
        "        # Ensure 'predicted_relevance' column is created and cast to float\n",
        "        if 'predicted_relevance' not in results.columns:\n",
        "            results['predicted_relevance'] = 0.0\n",
        "\n",
        "        # Check if there are any results before predicting relevance\n",
        "        if not results.empty:\n",
        "            # Predict relevance and assign to results DataFrame using .loc\n",
        "            results.loc[:, 'predicted_relevance'] = model.predict(results[['sentiment']])\n",
        "\n",
        "            # Filter and sort results\n",
        "            results = results.sort_values(by='predicted_relevance', ascending=False)\n",
        "\n",
        "    if results.empty:\n",
        "        print(f\"No results found for '{search_term}'. Try these:\")\n",
        "        # Suggest related terms or categories (implementation not shown here)\n",
        "    else:\n",
        "        if 'predicted_relevance' in results.columns:\n",
        "            results['relevance_percent'] = (results['predicted_relevance'] / results['predicted_relevance'].max()) * 100\n",
        "            with pd.option_context('display.max_rows', None, 'display.max_colwidth', 0):\n",
        "                display(results[['hscode', 'description', 'section', 'sentiment', 'relevance_percent']])\n",
        "        else:\n",
        "            print(\"No predicted relevance found for the search results.\")\n",
        "\n",
        "    # Suggest related terms only if the search term is not numeric\n",
        "    if not search_term.isdigit():\n",
        "        try:\n",
        "            suggestions = custom_model.wv.most_similar(search_term, topn=5)\n",
        "            print(\"Related terms:\", suggestions)\n",
        "        except KeyError:\n",
        "            print(f\"No related terms found for '{search_term}' in the word embedding model.\")\n",
        "\n",
        "    # Re-display the search box and button\n",
        "    display_search_box()\n",
        "\n",
        "def display_search_box():\n",
        "    # Create searchbox widget with updated placeholder text\n",
        "    search_box = widgets.Text(placeholder='Enter HS code (4 digits) or words', layout=widgets.Layout(width='300px'))\n",
        "\n",
        "    # Create search button widget\n",
        "    search_button = widgets.Button(description='Search', button_style='success', layout=widgets.Layout(width='100px'))\n",
        "\n",
        "    # Define button click event\n",
        "    def on_button_click(b):\n",
        "        clear_output()\n",
        "        search_term = search_box.value.lower()\n",
        "        search_descriptions(search_term)\n",
        "\n",
        "    search_button.on_click(on_button_click)\n",
        "\n",
        "    # Create a fixed layout for the search box and button\n",
        "    fixed_layout = widgets.Layout(position='fixed', top='0px', width='100%', background_color='#f0f0f0', padding='10px')\n",
        "    search_box_container = widgets.HBox([search_box, search_button], layout=fixed_layout)\n",
        "\n",
        "    # Display searchbox and button with fixed layout\n",
        "    display(search_box_container)\n",
        "\n",
        "# Add custom CSS for additional styling\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        "    .widget-hbox {\n",
        "        justify-content: center;\n",
        "        align-items: center;\n",
        "    }\n",
        "    .widget-text {\n",
        "        font-size: 14px;\n",
        "        padding: 5px;\n",
        "    }\n",
        "    .widget-button {\n",
        "        font-size: 14px;\n",
        "        padding: 5px;\n",
        "    }\n",
        "    .title {\n",
        "        font-size: 24px;\n",
        "        font-weight: bold;\n",
        "        text-align: center;\n",
        "        margin-bottom: 20px;\n",
        "    }\n",
        "</style>\n",
        "\"\"\"))\n",
        "\n",
        "# Display the title\n",
        "display(HTML('<div class=\"title\">WCO HS 2022 Explorer</div>'))\n",
        "\n",
        "# Initial display of the search box and button\n",
        "display_search_box()\n"
      ]
    }
  ]
}